###
# ** NOTE NOTE NOTE!! ** - THIS FILE IS SAMPLE INVENTORY FOR INI FILE BASED INVENTORY - Please refer
# **   https://github.com/Juniper/contrail-ansible/wiki/Quickstart
# ** A DIRECTORY IN THE NAME OF "my-inventory" is not related to this file but that is a sample for directory based inventory **
###

###################################################
# Define your nodes here ##########################
###################################################

# Enable contrail-repo when required - this will start a contrail apt or yum repo container on specified node
# This repo will be used by other nodes on installing any packages in the node
# setting up contrail-cni need this repo enabled
# NOTE: Repo is required only for mesos and nested mode kubernetes
;[contrail-repo]
;192.168.0.24

##
# Only enable if you setup with openstack (when cloud_orchestrator is openstack)
##
;[openstack-controllers]
;192.168.0.23 ansible_user=root

[contrail-controllers]
192.168.0.24

[contrail-analyticsdb]
192.168.0.24

[contrail-analytics]
192.168.0.24

[contrail-kubernetes]
192.168.0.24

[contrail-compute]
192.168.0.25
192.168.0.26

###################################################
# Setup all variables below #######################
###################################################

[all:vars]
###################################################
# Docker configurations
##
; docker registry
docker_registry=10.84.34.155:5000
docker_registry_insecure=True

; install docker from package rather than installer from get.docker.com which is default method
docker_install_method=package

; install docker-py or equivalent (needed by the docker_container ansible module
; to work) using either "pip" or the yum/apt repo using "package" module. Valid
; options are "pip" or "package". Defaults to "package".
; NOTE: If "package" is being used, please ensure contrail_apt_repo points to a
; apt/yum repo containing packages from the contrail-cloud-docker.tgz. SM/SMLite
; does this automatically. If using contrail-ansible directly it is recommended
; to use "pip" for this variable
docker_py_pkg_install_method=pip
; contrail_apt_repo="http://puppet/contrail/repo/contrail contrail main"

###################################################
# Ansible specific vars
##
; ansible connection details
ansible_user=root
ansible_connection=ssh
ansible_become=true
;ansible_ssh_private_key_file=~/.ssh/id_rsa

###################################################
# Common settings for contrail
##
; os_release - operating system release - ubuntu 14.04, ubuntu 16.04, centos 7.1, centos 7.2
os_release = ubuntu14.04

; contrail_compute_mode - the values are bare_metal to have bare_metal agent setup and "container" for agent container
; default is bare_metal
;contrail_compute_mode=bare_metal

; controller_ip - controller ip address, in case of multi-controller setup this should be the vip (load balanced ip address).
; if not configured, ansible use first ip address from [contrail-controllers]
controller_ip=192.168.0.24

; contrail version
contrail_version=4.0.0.0-3011

; cloud_orchestrator - cloud orchestrators to be setup
; Valid cloud orchestrators:
; kubernetes, mesos, openstack, openshift
cloud_orchestrator=kubernetes

; compute vrouter interface - physical interface name that hosting compute ip address
vrouter_physical_interface=eth0
; Toragent config
;tor_agent = { '10.204.216.34': [ {'tor_ip': '10.204.221.35', 'tor_agent_id': '1', 'tor_tsn_ip': '10.204.221.33', 'tor_ovs_port': '9999', 'tor_ovs_protocol': 'tcp', 'tor_name': 'contrail-tor-1', 'tor_http_server_port': '9090', 'tor_vendor_name': 'Juniper', 'tor_tsn_name':'tsn1', 'tor_agent_ovs_ka': '1000', 'tor_agent_name':'agent1', 'tor_tunnel_ip':'10.204.216.54', 'tor_product_name':'qfx1'} , {'tor_ip': '10.204.221.35', 'tor_agent_id': '2', 'tor_tsn_ip': '10.204.221.33', 'tor_ovs_port': '9999', 'tor_ovs_protocol': 'tcp', 'tor_name': 'contrail-tor-2', 'tor_http_server_port': '9090', 'tor_vendor_name': 'Juniper', 'tor_tsn_name':'tsn2', 'tor_agent_ovs_ka': '1000','tor_agent_name':'agent2', 'tor_tunnel_ip':'10.204.216.55', 'tor_product_name':'qfx2'}] }

; custom image for kube-manager - image with ubuntu 16.04 and systemd
; contrail_kube_manager_image=10.84.34.155:5000/contrail-kube-manager-u16.04:4.0.0.0-3016

; custom image for mesos-manager - image with ubuntu 16.04 and systemd
; contrail_mesos_manager_image=10.84.34.155:5000/contrail-mesos-manager-u16.04:4.0.0.0-3016

; To configure custom webui http port
; webui_config = {'http_listen_port': 8085, 'webui_storage_enable' : false}

###################################################
# Openstack specific configuration
##
;contrail_install_packages_url=http://10.84.5.120/github-build/mainline/3023/ubuntu-14-04/mitaka/contrail-install-packages_4.0.0.0-3023~mitaka_all.deb
;keystone_config = {'ip': '192.168.0.23', 'admin_password': 'contrail123', 'auth_protocol': 'http'}

###################################################

# SSL Cert Configuration (Path to copy SSL certs to containers/bare metal)
# User has to generate the certificates with following name for each server in the cluster and
# keep it under the path the specified in sl_certs_src_dir directory accessible to ansible
# ssl_ca Name: ca-cert.pem
# ssl_cert Name: <hostname>.pem
# ssl_key Name: <hostname>-privkey.pem
;ssl_certs_src_dir=/etc/contrail_smgr/puppet/ssl

###################################################
# XMPP Auth Configuration
;xmpp_auth_enable=false
;xmpp_dns_auth_enable=false

# Sandesh SSL Enable/Disable
;sandesh_ssl_enable=false

# Introspect SSL Enable/Disable
;introspect_ssl_enable=false

# Haproxy SSL termination for api-server
# apiserver_auth_protocol - https or http Default: True
# apiserver_insecure - Boolean Default: False
; apiserver_auth_protocol=http
; apiserver_insecure=False

# Qos queueing configuration
;qos =  {
;       '192.168.0.25': [ {'hardware_q_id': '3', 'logical_queue':['1', '6-10', '12-15']},
;                         {'hardware_q_id': '5', 'logical_queue':['2']},
;                         {'hardware_q_id': '8', 'logical_queue':['3-5']},
;                         {'hardware_q_id': '1', 'default': 'True'}],
;       '192.168.0.26': [ {'hardware_q_id': '2', 'logical_queue':['1', '3-8', '10-15']},
;                         {'hardware_q_id': '6', 'logical_queue':['17-20'], 'default': 'True'}]
;       }

# Qos scheduling configuration
;qos_niantic =  {
;       '192.168.0.25': [ { 'priority_id': '1', 'scheduling': 'strict', 'bandwidth': '0'},
;                         { 'priority_id': '2', 'scheduling': 'rr', 'bandwidth': '20'},
;                         { 'priority_id': '3', 'scheduling': 'rr', 'bandwidth': '10'}],
;       '192.168.0.26' :[ { 'priority_id': '1', 'scheduling': 'strict', 'bandwidth': '0'},
;                         { 'priority_id': '1', 'scheduling': 'rr', 'bandwidth': '30'}]
;               }

# SRIOV Configuration
;sriov = {
;        '192.168.0.25': [{'interface': 'p4p1', 'physnets': ['physnet3', 'physnet4'], 'VF': '5'},
;                         {'interface': 'em1', 'physnets': ['physnet1', 'physnet2'], 'VF': '7'}]
;        }

###################################################
# Kubernetes cluster configuration
##

# Underlay Contrail Api Server to which this kubernetes instance should
# connect to. This is to be set for nested kubernetes installation.
;[kubernetes-contrail-controllers]
;192.168.0.24

# The IP subnet reserved for use by kubernetes for internal cluster management
# and housekeeping.
;nested_cluster_private_network=<subnet CIDR>

# Virtual Network in which the Kubernetes cluster should be provisioned.
;nested_cluster_network={domain: <name>, project: <name>, name: <name>}

# Name of the kubernetes cluster being provisioned.
;kubernetes_cluster_name=<name>

# Access token to connect to Kuberenetes API server.
;kubernetes_access_token=<token>

# Access token to connect to Kuberenetes API server.
;nested_mode=true

# Kubernetes FloatingIpPool to be used for service/ingress.
# Example:kubernetes_public_fip_pool: {domain: domain-name, project: project-name, network: network-name, name: fip-pool-name}
#
;kubernetes_public_fip_pool: {domain: <>, project: <>, network: <>, name: <>}

# Kubernetes cluster project fq-name.
# Example: kubernetes_cluster_project: {domain: domain-name, project: project-name}
#
;kubernetes_cluster_project: {domain: <>, project: <>}

# Kubernetes pod subnet.
# If not configured, default value of 10.32.0.0/12 is used.
#
;kubernetes_pod_subnet: "10.32.0.0/12"

# Kubernetes service subnet
# If not configured, default value of 10.96.0.0/12 is used.
#
;kubernetes_service_subnet: "10.96.0.0/12"

;global_config = {
;        'analyticsdb_cassandra_user': '<analyticsdb_cassandra_user>',
;        'analyticsdb_cassandra_password': '<analyticsdb_cassandra_password>'
;        'redis_password': '<redis_password>'
;}

#OPTIONAL Virtual gateway CONFIGURATION
#=======================================

#Section vgw is only relevant when you want to use virtual gateway feature.
#You can use one of your compute node as  gateway .

#Definition for the Key used
#-------------------------------------
#vn: Virtual Network fully qualified name. This particular VN will be used by VGW.
#ipam_subnets: Subnets used by vn. It can be single or multiple
#gateway_routes: If any route is present then only those routes will be published
#by VGW or Default route (0.0.0.0) will be published

;vgw =  {
;   '192.168.0.25': {'vgw1':{'vn':'default-domain:admin:public:public', 'ipam_subnets': ['10.204.220.128/29', '10.204.220.136/29'], 'gateway_routes': ['8.8.8.0/24', '1.1.1.0/24'] },
;                   'vgw2':{'vn':'default-domain:admin:public1:public1', 'ipam_subnets': ['10.204.220.144/29']}},
;   '192.168.0.26': {'vgw2':{'vn':'default-domain:admin:public1:public1', 'ipam_subnets': ['10.204.220.144/29']}}
;       }
